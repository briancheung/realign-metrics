{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-mbm6mas_\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-mbm6mas_\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: ftfy in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from clip==1.0) (6.1.3)\n",
      "Requirement already satisfied: packaging in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from clip==1.0) (23.2)\n",
      "Requirement already satisfied: regex in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from clip==1.0) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from clip==1.0) (4.66.2)\n",
      "Requirement already satisfied: torch in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from clip==1.0) (1.13.1)\n",
      "Requirement already satisfied: torchvision in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from clip==1.0) (0.14.1)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: typing-extensions in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from torch->clip==1.0) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from torch->clip==1.0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from torch->clip==1.0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from torch->clip==1.0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from torch->clip==1.0) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->clip==1.0) (68.2.2)\n",
      "Requirement already satisfied: wheel in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->clip==1.0) (0.41.2)\n",
      "Requirement already satisfied: numpy in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from torchvision->clip==1.0) (1.26.4)\n",
      "Requirement already satisfied: requests in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from torchvision->clip==1.0) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from torchvision->clip==1.0) (10.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/home/ssuresh/miniconda3/envs/thingsvision/lib/python3.9/site-packages (from requests->torchvision->clip==1.0) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 14:24:34.061472: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-07 14:24:38.048490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22048 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:31:00.0, compute capability: 8.6\n",
      "2025-03-07 14:24:38.049269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21594 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:ca:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from thingsvision import get_extractor\n",
    "from thingsvision.utils.storing import save_features\n",
    "from thingsvision.utils.data import ImageDataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from typing import Any, Dict, List, Optional, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the data directory\n",
    "\n",
    "I am using the test set of CIFAR100 as an example of input stimuli. The data is stored in the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Saved 0 images for test set\n",
      "Saved 1000 images for test set\n",
      "Saved 2000 images for test set\n",
      "Saved 3000 images for test set\n",
      "Saved 4000 images for test set\n",
      "Saved 5000 images for test set\n",
      "Saved 6000 images for test set\n",
      "Saved 7000 images for test set\n",
      "Saved 8000 images for test set\n",
      "Saved 9000 images for test set\n",
      "Finished saving all CIFAR-100 test images\n"
     ]
    }
   ],
   "source": [
    "# Set the paths\n",
    "data_dir = '../data/'  # Use the already defined image_dir from cell 4\n",
    "save_dir = '../data/cifar100_images'\n",
    "\n",
    "# Only download the test set of CIFAR-100 dataset\n",
    "test_dataset = datasets.CIFAR100(data_dir, train=False, download=True)\n",
    "\n",
    "# Create directories for the test set\n",
    "set_dir = os.path.join(save_dir, 'test')\n",
    "os.makedirs(set_dir, exist_ok=True)\n",
    "\n",
    "# Create directories for each class\n",
    "for class_idx in range(len(test_dataset.classes)):\n",
    "    class_dir = os.path.join(set_dir, test_dataset.classes[class_idx])\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "# Save each image from the test set\n",
    "for i, (img, label) in enumerate(test_dataset):\n",
    "    class_name = test_dataset.classes[label]\n",
    "    img_path = os.path.join(set_dir, class_name, f'image_{i}.png')\n",
    "    img.save(img_path)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(f'Saved {i} images for test set')\n",
    "\n",
    "print('Finished saving all CIFAR-100 test images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set your torch cache directory\n",
    "os.environ['TORCH_HOME'] = '../cache'\n",
    "\n",
    "#set your data directory where the images are stored\n",
    "image_dir = '../data/cifar100_images/test'\n",
    "\n",
    "#set the directory where the extracted features will be stored\n",
    "output_dir = '../activations/cifar100'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(\n",
    "    extractor: Any,\n",
    "    module_name: str,\n",
    "    image_path: str,\n",
    "    out_path: str,\n",
    "    batch_size: int,\n",
    "    flatten_activations: bool,\n",
    "    apply_center_crop: bool,\n",
    "    class_names: Optional[List[str]]=None,\n",
    "    file_names: Optional[List[str]]=None,\n",
    ") -> Union[np.ndarray, torch.Tensor]:\n",
    "    \"\"\"Extract features for a single layer.\"\"\"                                    \n",
    "    dataset = ImageDataset(\n",
    "        root=image_path,\n",
    "        out_path=out_path,\n",
    "        backend=extractor.get_backend(),\n",
    "        transforms=extractor.get_transformations(apply_center_crop=apply_center_crop, resize_dim=256, crop_dim=224),\n",
    "        class_names=class_names,\n",
    "        file_names=file_names,\n",
    "    )\n",
    "    batches = DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        backend=extractor.get_backend(),\n",
    "        )\n",
    "    features = extractor.extract_features(\n",
    "        batches=batches,\n",
    "        module_name=module_name,\n",
    "        flatten_acts=flatten_activations,\n",
    "        output_type=\"ndarray\", # or \"tensor\" (only applicable to PyTorch models)\n",
    "    )\n",
    "    return features\n",
    "\n",
    "def extract_all_layers(\n",
    "    model_name: str,\n",
    "    extractor: Any,\n",
    "    image_path: str,\n",
    "    out_path: str,\n",
    "    batch_size: int,\n",
    "    flatten_activations: bool,\n",
    "    apply_center_crop: bool,\n",
    "    layer: Any=nn.Linear,\n",
    "    layer_names: Optional[List[str]]=None,\n",
    "    file_format: str = \"npy\",\n",
    "    class_names: Optional[List[str]]=None,\n",
    "    file_names: Optional[List[str]]=None,\n",
    ") -> Dict[str, Union[np.ndarray, torch.Tensor]]:\n",
    "    \"\"\"Extract features for all selected layers and save them to disk.\"\"\"\n",
    "    features_per_layer = {}\n",
    "    \n",
    "    # If specific layer names are provided, extract only those layers\n",
    "    if layer_names:\n",
    "        for module_name, module in extractor.model.named_modules():\n",
    "            if module_name in layer_names:\n",
    "                features = extract_features(\n",
    "                    extractor=extractor,\n",
    "                    module_name=module_name,\n",
    "                    image_path=image_path,\n",
    "                    out_path=out_path,\n",
    "                    batch_size=batch_size,\n",
    "                    flatten_activations=flatten_activations,\n",
    "                    apply_center_crop=apply_center_crop,\n",
    "                    class_names=class_names,\n",
    "                    file_names=file_names,\n",
    "                )\n",
    "                features_per_layer[module_name] = features\n",
    "                save_features(features, out_path=f'{out_path}/{model_name}/{module_name}', file_format=file_format)\n",
    "    # Otherwise extract by layer type\n",
    "    else:\n",
    "        for l, (module_name, module) in enumerate(extractor.model.named_modules(), start=1):\n",
    "            if isinstance(module, layer):\n",
    "                # extract features for layer \"module_name\"\n",
    "                features = extract_features(\n",
    "                    extractor=extractor,\n",
    "                    module_name=module_name,\n",
    "                    image_path=image_path,\n",
    "                    out_path=out_path,\n",
    "                    batch_size=batch_size,\n",
    "                    flatten_activations=flatten_activations,\n",
    "                    apply_center_crop=apply_center_crop,\n",
    "                    class_names=class_names,\n",
    "                    file_names=file_names,\n",
    "                )\n",
    "                # if you want, replace for simplicity with e.g., [f'conv_{l:02d}'], [f'fc_{l:02d}'], or [f'layer_{l:02d}']\n",
    "                features_per_layer[f'{module_name}'] = features\n",
    "                # save features to disk\n",
    "                save_features(features, out_path=f'{out_path}/{model_name}/{module_name}', file_format=file_format)\n",
    "    return features_per_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: resnet50, Source: torchvision\n",
      "Using device:  cuda\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n",
      "=====================================================\n",
      "Model: mocov2-rn50, Source: ssl\n",
      "Using device:  cuda\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Identity()\n",
      ")\n",
      "=====================================================\n",
      "Model: clip, Source: custom\n",
      "Using device:  cuda\n",
      "visual.conv1\n",
      "visual.ln_pre\n",
      "visual.transformer\n",
      "visual.transformer.resblocks\n",
      "visual.transformer.resblocks.0\n",
      "visual.transformer.resblocks.0.attn\n",
      "visual.transformer.resblocks.0.attn.out_proj\n",
      "visual.transformer.resblocks.0.ln_1\n",
      "visual.transformer.resblocks.0.mlp\n",
      "visual.transformer.resblocks.0.mlp.c_fc\n",
      "visual.transformer.resblocks.0.mlp.gelu\n",
      "visual.transformer.resblocks.0.mlp.c_proj\n",
      "visual.transformer.resblocks.0.ln_2\n",
      "visual.transformer.resblocks.1\n",
      "visual.transformer.resblocks.1.attn\n",
      "visual.transformer.resblocks.1.attn.out_proj\n",
      "visual.transformer.resblocks.1.ln_1\n",
      "visual.transformer.resblocks.1.mlp\n",
      "visual.transformer.resblocks.1.mlp.c_fc\n",
      "visual.transformer.resblocks.1.mlp.gelu\n",
      "visual.transformer.resblocks.1.mlp.c_proj\n",
      "visual.transformer.resblocks.1.ln_2\n",
      "visual.transformer.resblocks.2\n",
      "visual.transformer.resblocks.2.attn\n",
      "visual.transformer.resblocks.2.attn.out_proj\n",
      "visual.transformer.resblocks.2.ln_1\n",
      "visual.transformer.resblocks.2.mlp\n",
      "visual.transformer.resblocks.2.mlp.c_fc\n",
      "visual.transformer.resblocks.2.mlp.gelu\n",
      "visual.transformer.resblocks.2.mlp.c_proj\n",
      "visual.transformer.resblocks.2.ln_2\n",
      "visual.transformer.resblocks.3\n",
      "visual.transformer.resblocks.3.attn\n",
      "visual.transformer.resblocks.3.attn.out_proj\n",
      "visual.transformer.resblocks.3.ln_1\n",
      "visual.transformer.resblocks.3.mlp\n",
      "visual.transformer.resblocks.3.mlp.c_fc\n",
      "visual.transformer.resblocks.3.mlp.gelu\n",
      "visual.transformer.resblocks.3.mlp.c_proj\n",
      "visual.transformer.resblocks.3.ln_2\n",
      "visual.transformer.resblocks.4\n",
      "visual.transformer.resblocks.4.attn\n",
      "visual.transformer.resblocks.4.attn.out_proj\n",
      "visual.transformer.resblocks.4.ln_1\n",
      "visual.transformer.resblocks.4.mlp\n",
      "visual.transformer.resblocks.4.mlp.c_fc\n",
      "visual.transformer.resblocks.4.mlp.gelu\n",
      "visual.transformer.resblocks.4.mlp.c_proj\n",
      "visual.transformer.resblocks.4.ln_2\n",
      "visual.transformer.resblocks.5\n",
      "visual.transformer.resblocks.5.attn\n",
      "visual.transformer.resblocks.5.attn.out_proj\n",
      "visual.transformer.resblocks.5.ln_1\n",
      "visual.transformer.resblocks.5.mlp\n",
      "visual.transformer.resblocks.5.mlp.c_fc\n",
      "visual.transformer.resblocks.5.mlp.gelu\n",
      "visual.transformer.resblocks.5.mlp.c_proj\n",
      "visual.transformer.resblocks.5.ln_2\n",
      "visual.transformer.resblocks.6\n",
      "visual.transformer.resblocks.6.attn\n",
      "visual.transformer.resblocks.6.attn.out_proj\n",
      "visual.transformer.resblocks.6.ln_1\n",
      "visual.transformer.resblocks.6.mlp\n",
      "visual.transformer.resblocks.6.mlp.c_fc\n",
      "visual.transformer.resblocks.6.mlp.gelu\n",
      "visual.transformer.resblocks.6.mlp.c_proj\n",
      "visual.transformer.resblocks.6.ln_2\n",
      "visual.transformer.resblocks.7\n",
      "visual.transformer.resblocks.7.attn\n",
      "visual.transformer.resblocks.7.attn.out_proj\n",
      "visual.transformer.resblocks.7.ln_1\n",
      "visual.transformer.resblocks.7.mlp\n",
      "visual.transformer.resblocks.7.mlp.c_fc\n",
      "visual.transformer.resblocks.7.mlp.gelu\n",
      "visual.transformer.resblocks.7.mlp.c_proj\n",
      "visual.transformer.resblocks.7.ln_2\n",
      "visual.transformer.resblocks.8\n",
      "visual.transformer.resblocks.8.attn\n",
      "visual.transformer.resblocks.8.attn.out_proj\n",
      "visual.transformer.resblocks.8.ln_1\n",
      "visual.transformer.resblocks.8.mlp\n",
      "visual.transformer.resblocks.8.mlp.c_fc\n",
      "visual.transformer.resblocks.8.mlp.gelu\n",
      "visual.transformer.resblocks.8.mlp.c_proj\n",
      "visual.transformer.resblocks.8.ln_2\n",
      "visual.transformer.resblocks.9\n",
      "visual.transformer.resblocks.9.attn\n",
      "visual.transformer.resblocks.9.attn.out_proj\n",
      "visual.transformer.resblocks.9.ln_1\n",
      "visual.transformer.resblocks.9.mlp\n",
      "visual.transformer.resblocks.9.mlp.c_fc\n",
      "visual.transformer.resblocks.9.mlp.gelu\n",
      "visual.transformer.resblocks.9.mlp.c_proj\n",
      "visual.transformer.resblocks.9.ln_2\n",
      "visual.transformer.resblocks.10\n",
      "visual.transformer.resblocks.10.attn\n",
      "visual.transformer.resblocks.10.attn.out_proj\n",
      "visual.transformer.resblocks.10.ln_1\n",
      "visual.transformer.resblocks.10.mlp\n",
      "visual.transformer.resblocks.10.mlp.c_fc\n",
      "visual.transformer.resblocks.10.mlp.gelu\n",
      "visual.transformer.resblocks.10.mlp.c_proj\n",
      "visual.transformer.resblocks.10.ln_2\n",
      "visual.transformer.resblocks.11\n",
      "visual.transformer.resblocks.11.attn\n",
      "visual.transformer.resblocks.11.attn.out_proj\n",
      "visual.transformer.resblocks.11.ln_1\n",
      "visual.transformer.resblocks.11.mlp\n",
      "visual.transformer.resblocks.11.mlp.c_fc\n",
      "visual.transformer.resblocks.11.mlp.gelu\n",
      "visual.transformer.resblocks.11.mlp.c_proj\n",
      "visual.transformer.resblocks.11.ln_2\n",
      "visual.ln_post\n",
      "visual\n",
      "None\n",
      "=====================================================\n",
      "Model: alexnet, Source: torchvision\n",
      "Using device:  cuda\n",
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "models = [{'model_name':'resnet50', 'source':'torchvision', 'model_parameters':None},\n",
    "          {'model_name':'mocov2-rn50', 'source':'ssl', 'model_parameters':None},\n",
    "          {'model_name':'clip', 'source':'custom', 'model_parameters':{'variant': 'ViT-B/32'}},\n",
    "          {'model_name':'alexnet', 'source':'torchvision', 'model_parameters':None}]\n",
    "\n",
    "for model in models:\n",
    "    model_name = model['model_name']\n",
    "    source = model['source']\n",
    "    model_parameters = model.get('model_parameters', None)\n",
    "    print(f\"Model: {model_name}, Source: {source}\")\n",
    "    extractor = get_extractor(\n",
    "        model_name=model_name,\n",
    "        source=source,\n",
    "        device=device,\n",
    "        pretrained=True,\n",
    "        model_parameters=model_parameters\n",
    "    )\n",
    "    print(extractor.show_model())\n",
    "    print(\"=====================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: resnet50, Source: torchvision\n",
      "Using device:  cuda\n",
      "\n",
      "...Creating dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 40/40 [02:32<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Features successfully extracted for all 10000 images in the database.\n",
      "\n",
      "Output directory did not exist. Creating directories to save features...\n",
      "\n",
      "...Features successfully saved to disk.\n",
      "\n",
      "Model: mocov2-rn50, Source: ssl\n",
      "Using device:  cuda\n",
      "\n",
      "...Creating dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 40/40 [00:30<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Features successfully extracted for all 10000 images in the database.\n",
      "\n",
      "Output directory did not exist. Creating directories to save features...\n",
      "\n",
      "...Features successfully saved to disk.\n",
      "\n",
      "Model: clip, Source: custom\n",
      "Using device:  cuda\n",
      "\n",
      "...Creating dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 40/40 [00:26<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Features successfully extracted for all 10000 images in the database.\n",
      "\n",
      "Output directory did not exist. Creating directories to save features...\n",
      "\n",
      "...Features successfully saved to disk.\n",
      "\n",
      "Model: alexnet, Source: torchvision\n",
      "Using device:  cuda\n",
      "\n",
      "...Creating dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 100%|██████████| 40/40 [00:22<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Features successfully extracted for all 10000 images in the database.\n",
      "\n",
      "Output directory did not exist. Creating directories to save features...\n",
      "\n",
      "...Features successfully saved to disk.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_dir = '../activations/cifar100' #set the directory where the extracted features will be stored\n",
    "image_dir = '../data/cifar100_images/test' # set the directory where the input are stored\n",
    "pretrained = True # use pretrained model weights\n",
    "model_path = None # if pretrained = False (i.e., randomly initialized weights) set path to model weights\n",
    "batch_size = 256 # use a power of two (this can be any size, depending on the number of images for which you aim to extract features)\n",
    "apply_center_crop = True # center crop images (set to False, if you don't want to center-crop images)\n",
    "flatten_activations = True # whether or not features (e.g., of Conv layers) should be flattened\n",
    "class_names = None  # optional list of class names for class dataset\n",
    "file_names = None # optional list of file names according to which features should be sorted\n",
    "file_format = \"npy\" # format with which to save features to disk (can be set to \"mat\", \"txt\", \"npy\", \"hdf5\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "models = [{'model_name':'resnet50', 'source':'torchvision', 'model_parameters':None, 'layers_to_extract':['fc']},\n",
    "          {'model_name':'mocov2-rn50', 'source':'ssl', 'model_parameters':None, 'layers_to_extract':['fc']},\n",
    "          {'model_name':'clip', 'source':'custom', 'model_parameters':{'variant': 'ViT-B/32'}, 'layers_to_extract':['visual']},\n",
    "          {'model_name':'alexnet', 'source':'torchvision', 'model_parameters':None, 'layers_to_extract':['classifier.4']}]\n",
    "\n",
    "for model in models:\n",
    "    model_name = model['model_name']\n",
    "    source = model['source']\n",
    "    model_parameters = model.get('model_parameters', None)\n",
    "    layers_to_extract = model['layers_to_extract']\n",
    "    print(f\"Model: {model_name}, Source: {source}\")\n",
    "    extractor = get_extractor(\n",
    "        model_name=model_name,\n",
    "        source=source,\n",
    "        device=device,\n",
    "        pretrained=True,\n",
    "        model_parameters=model_parameters\n",
    "    )\n",
    "    extract_all_layers(\n",
    "        model_name=model_name,\n",
    "        extractor=extractor,\n",
    "        image_path=image_dir,\n",
    "        out_path=output_dir,\n",
    "        batch_size=batch_size,\n",
    "        flatten_activations=True,\n",
    "        apply_center_crop=False,\n",
    "        layer_names=layers_to_extract,\n",
    "        file_format=\"npy\",\n",
    "    ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thingsvision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
