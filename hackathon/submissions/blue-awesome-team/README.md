# Re-Align Workshop Hackathon

This hackathon focuses on understanding and comparing **representational alignment** across a wide variety of vision models. Participants will join either the **Blue Team** or the **Red Team** and provide JSON submissions that demonstrate the largest uniform set of models (Blue) or greatest differentiation among those models (Red).

---

## Hackathon Overview
We have ~1300 vision models available for use, plus metadata about each model’s architecture, training data, and more. The hackathon aims to answer:

1. **When are models “functionally identical” (indistinguishable) in their behaviors?**  
2. **When do models show meaningful differences—and how can we highlight those differences with carefully chosen stimuli?**

**Key points:**
- **Blue Team** seeks **universality** among models.  
- **Red Team** seeks **variability** among models.  

---

## Hackathon Goal

- **Blue Team**: 
  - **Objective**: Submit a **set of models** that appear to be **functionally identical** on a given (or chosen) stimulus set.

- **Red Team**: 
  - **Objective**: Choose **stimuli** (or a stimulus set) that highlight how a group of models differs in functionally meaningful ways.

Your final submission (in JSON format) should reflect how you identified these models (Blue) or how you selected these stimuli (Red), along with a brief rationale. We look forward to seeing how each team tackles the question of **representational alignment**—whether it’s finding a surprising uniformity among models or uncovering their hidden differences.